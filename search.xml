<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/07/08/hello-world/"/>
      <url>/2023/07/08/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2023/06/19/shen-du-xue-xi-fan-xiang-chuan-bo/"/>
      <url>/2023/06/19/shen-du-xue-xi-fan-xiang-chuan-bo/</url>
      
        <content type="html"><![CDATA[<hr><h2 id="title-深度学习–反向传播date-2023-x2F-7-x2F-9keywords-深度学习copyright-falsecopyright-author-zhoujcopyright-info-此文章版权归zhouj所有，如有转载，请注明来自原作者"><a href="#title-深度学习–反向传播date-2023-x2F-7-x2F-9keywords-深度学习copyright-falsecopyright-author-zhoujcopyright-info-此文章版权归zhouj所有，如有转载，请注明来自原作者" class="headerlink" title="title:深度学习–反向传播date:2023&#x2F;7&#x2F;9keywords:深度学习copyright:falsecopyright_author:zhoujcopyright_info:此文章版权归zhouj所有，如有转载，请注明来自原作者"></a>title:深度学习–反向传播<br>date:2023&#x2F;7&#x2F;9<br>keywords:深度学习<br>copyright:false<br>copyright_author:zhouj<br>copyright_info:此文章版权归zhouj所有，如有转载，请注明来自原作者</h2><h1 id="深度学习–反向传播"><a href="#深度学习–反向传播" class="headerlink" title="深度学习–反向传播"></a>深度学习–反向传播</h1><p>使用Matt Mazur的例子，来简单推导过程</p><p><img src="https://i.imgtg.com/2023/06/14/OBGvnt.png" alt="OBGvnt.png"></p><p><strong>先初始化权重和偏置量</strong></p><p><img src="https://i.imgtg.com/2023/06/14/OBGt5v.png" alt="OBGt5v.png"></p><h2 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a><strong>前向传播</strong></h2><p><strong>1.计算h<sub>1</sub>所有输入：</strong><br>$$<br>net_{h1} &#x3D; w_{1} * i_{1} + w_{2} * i_{2} + b_{1} * 1<br>$$<br>带入权重与偏置量数据：<br>$$<br>net_{h1} &#x3D; 0.15 * 0.05 + 0.2 * 0.1 + 0.35 * 1 &#x3D; 0.3775<br>$$<br><strong>2.利用logistic函数计算得到h<sub>1</sub>的输出：</strong><br>$$<br>out_{h1} &#x3D;\frac{1}{1+e^{-net_{h1}}} &#x3D; \frac{1}{1+e^{-0.3775}} &#x3D; 0.593269992<br>$$<br><strong>3.利用同样的方法得到</strong><br>$$<br>out_{h2} &#x3D; 0.596884378<br>$$<br><strong>4.使用隐藏层神经元的输出作为输入，用同样的方法给出o<sub>1</sub>的输出：</strong><br>$$<br>net_{o_{1}} &#x3D; w_{5} * out_{h_{1}} + w_{6} * out_{h_{2}} + b_{2} * 1<br>$$<br>带入数据得：<br>$$<br>net_{o_{1}} &#x3D; 0.4 * 0.593269992 + 0.45 * 0.596884378 + 0.6 &#x3D;1.105905967<br>$$<br>利用 logistic函数得出其输出为：<br>$$<br>out_{o_{1}} &#x3D; \frac{1}{1+e^{-net_{o_{1}}}} &#x3D; \frac{1}{1+e^{-1.105905967}} &#x3D; 0.75136507<br>$$</p><p>同理可得o<sub>2</sub>的输出：<br>$$<br>out_{o_{2}} &#x3D; 0.772928465<br>$$<br><strong>5.统计所有误差</strong><br>$$<br>E_{total} &#x3D; \sum\frac{1}{2}(target - output)^2<br>$$<br>带入数据，o<sub>1</sub>原始输出为0.01，神经网络的输出为0.75136507，计算出误差为：<br>$$<br>E_{o_{1}} &#x3D; \sum\frac{1}{2}(0.01 - 0.75136507)^2 &#x3D; 0.298371109<br>$$<br>同理可得:<br>$$<br>E_{o_{2}} &#x3D; 0.023560026<br>$$<br>综上所述：<strong>总误差</strong>：<br>$$<br>E_{total} &#x3D; E_{o_{1}} + E_{o_{2}} &#x3D; 0.298371109<br>$$</p><h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><h2 id="输出层"><a href="#输出层" class="headerlink" title="输出层"></a>输出层</h2><p>反过来往前推，对于w5，想知道其改变对总误差有多少影响，可以得到：<br>$$<br>\frac{dE_{total}}{dw_{5}}<br>$$<br>通过链式法则可以得到：<br>$$<br>\frac{dE_{total}}{dw_{5}} &#x3D; \frac{dE_{total}}{dout_{o_{1}}} * \frac{dout_{o_{1}}}{dnet_{o_{1}}} * \frac{dnet_{o_{1}}}{dw_{5}}<br>$$<br>其实一直在做的就是如图所示：</p><p><img src="https://i.imgtg.com/2023/06/14/OBG4Kq.png" alt="OBG4Kq.png"></p><p>拆分成每一部分来分析，首先：<br>$$<br>E_{total} &#x3D; \frac{1}{2}(target_{o_{1}}-out_{o_{1}})^2 + \frac{1}{2}(target_{o_{2}}-out_{o_{2}})^2<br>$$<br>对于多变量函数，我们需要使用偏导数来表示函数对每个参数的变化率<br>$$<br>\frac{\partial E_{total}}{\partial out_{o_{1}}} &#x3D; 2<em>\frac{1}{2}(target_{o_{1}}-out_{o_{1}})^{2-1}</em>-1 +0<br>$$</p><p>$$<br>\frac {\partial E_{total}}{\partial out_{o_{1}}} &#x3D; -(target_{o_{1}}-out_{o_{1}})&#x3D;-(0.01-0.75136507)&#x3D;0.74136507<br>$$</p><p>由logistic函数可知：<br>$$<br>out_{o_{1}}&#x3D;\frac {1}{1+e^{-net_{o_{1}}}}<br>$$</p><p>$$<br>\frac {\partial out_{o_{1}}}{\partial net_{o_{1}}}&#x3D;out_{o_{1}}(1-out_{o_{1}})&#x3D;0.75136507(1-0.75136507)&#x3D;0.186815602<br>$$</p><p>由net<sub>o1</sub>输入公式可得：<br>$$<br>net_{o_{1}}&#x3D;w_{5}*out_{h1}+w_{6}*out_{h2}+b_{2}*1<br>$$</p><p>$$<br>\frac{\partial net_{o_{1}}}{\partial w_{5}}&#x3D;1*out_{h1}*w_{5}^{(1-1)}+0+0&#x3D;out_{h1}&#x3D;0.593269992<br>$$</p><p>所以可以得到：<br>$$<br>\frac{\partial E_{total}}{\partial w_{5}}&#x3D;\frac{\partial E_{total}}{\partial out_{o_{1}}}<em>\frac{\partial out_{o_{1}}}{\partial net_{o_{1}}}<em>\frac{\partial net_{o_{1}}}{\partial w_{5}}&#x3D;0.74136507</em>0.186815602</em>0.593269992&#x3D;0.082167041<br>$$<br>为了减少误差，可以从当前的权重减去这个值（可以选择一个学习率，比如设置为0.5）得：<br>$$<br>w_{5}^+&#x3D;w_{5}-\eta<em>\frac{\partial E_{total}}{\partial w_{5}}&#x3D;0.4-0.5</em>0.082167041&#x3D;0.35891648<br>$$<br>同理可得：<br>$$<br>w_{6}^+&#x3D;0.408666186<br>$$</p><p>$$<br>w_{7}^+&#x3D;0.511301270<br>$$</p><p>$$<br>w_{8}^+&#x3D;0.561370121<br>$$</p><p>在有新权重导入隐藏层神经元（当继续下面的反向传播算法时，使用原始权重，而不是更新的权重）之后，执行神经网络中的实际更新。</p><h2 id="隐藏层"><a href="#隐藏层" class="headerlink" title="隐藏层"></a>隐藏层</h2><p>我们需要算：<br>$$<br>\frac{\partial E_{total}}{\partial w_{1}}&#x3D;\frac{\partial E_{total}}{\partial out_{h1}}*\frac{\partial out_{h1}}{\partial net_{h1}}*\frac{\partial net_{h1}}{\partial w_{1}}<br>$$<br>从图中可以看清楚：</p><p><img src="https://i.imgtg.com/2023/06/14/OBGDSc.png" alt="OBGDSc.png"></p><p>由于：<br>$$<br>\frac{\partial E_{total}}{\partial out_{h1}}&#x3D;\frac{\partial E_{o_{1}}}{\partial out_{h1}}+\frac{E_{o_{2}}}{\partial out_{h1}}<br>$$<br>可拆分计算：<br>$$<br>\frac{\partial E_{o_{1}}}{\partial out_{h1}}&#x3D;\frac{\partial E_{o_{1}}}{\partial net_{o_{1}}}*\frac{\partial net_{o_{1}}}{\partial out_{h1}}<br>$$</p><p>$$<br>\frac{\partial E_{o_{1}}}{\partial net_{o_{1}}}&#x3D;\frac{\partial E_{o_{1}}}{\partial out_{o_{1}}}<em>\frac{\partial out_{o_{1}}}{\partial net_{o_{1}}}&#x3D;0.74136507</em>0.186815602&#x3D;0.148498562<br>$$</p><p>由于：<br>$$<br>net_{o_{1}}&#x3D;w_{5}*out_{h1}+w_{6}*out_{h2}+b_{2}*1<br>$$<br>可得：<br>$$<br>\frac{\partial net_{o_{1}}}{\partial out_{h1}}&#x3D;w_{5}&#x3D;0.40<br>$$<br>综合可得：<br>$$<br>\frac{\partial E_{o_{1}}}{\partial out_{h1}}&#x3D;\frac{\partial E_{o_{1}}}{\partial net_{o_{1}}}<em>\frac{\partial net_{o_{1}}}{\partial out_{h1}}&#x3D;0.138498562</em>0.40&#x3D;0.055399425<br>$$<br>同理可得：<br>$$<br>\frac{\partial E_{o_{2}}}{\partial out_{h1}}&#x3D;-0.019049119<br>$$<br>所以可以得到：<br>$$<br>\frac{\partial E_{total}}{\partial out_{h1}}&#x3D;\frac{\partial E_{o_{1}}}{\partial out_{h1}}+\frac{\partial E_{o_{2}}}{\partial out_{h1}}&#x3D;0.055399425+-0.019049119&#x3D;0.036350306<br>$$<br>通过logistic函数：<br>$$<br>out_{h1}&#x3D;\frac{1}{1+e^{-net_{h1}}}<br>$$<br>对net<sub>h1</sub>求偏导：<br>$$<br>\frac{\partial out_{h1}}{\partial net_{h1}}&#x3D;out_{h1}(1-out_{h1})&#x3D;0.59326999(1-0.59326999)&#x3D;0.241300709<br>$$<br>由公式可得：<br>$$<br>net_{h1}&#x3D;w_{1}*i_{1}+w_{2}*i_{2}+b_{1}*1<br>$$</p><p>$$<br>\frac{\partial net_{h1}}{w_{1}}&#x3D;i_{1}&#x3D;0.05<br>$$</p><p>综合可得：<br>$$<br>\frac{\partial E_{total}}{\partial w_{1}}&#x3D;\frac{\partial E_{total}}{out_{h1}}<em>\frac{\partial out_{h1}}{net_{h1}}<em>\frac{\partial net_{h1}}{\partial w_{1}}&#x3D;0.036350306</em>0.241300709</em>0.05&#x3D;0.000438568<br>$$<br>更新w<sub>1</sub>:<br>$$<br>w_{1}^+&#x3D;w_{1}-\eta<em>\frac{\partial E_{total}}{\partial w_{1}}&#x3D;0.15-0.5</em>0.000438568&#x3D;0.149780716<br>$$<br>同理可得：<br>$$<br>w_{2}^+&#x3D;0.19956143<br>$$</p><p>$$<br>w_{3}^+&#x3D;0.24975114<br>$$</p><p>$$<br>w_{4}^+&#x3D;0.29950229<br>$$</p><p>最后，更新了所有的权重！ 当最初前馈传播时输入为0.05和0.1，网络上的误差是0.298371109。 在第一轮反向传播之后，总误差现在下降到0.291027924</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
